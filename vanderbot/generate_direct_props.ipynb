{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests   # best library to manage HTTP transactions\n",
    "from bs4 import BeautifulSoup # web-scraping library\n",
    "import json\n",
    "from time import sleep\n",
    "import csv\n",
    "import math\n",
    "from fuzzywuzzy import fuzz # fuzzy logic matching\n",
    "from fuzzywuzzy import process\n",
    "import xml.etree.ElementTree as et # library to traverse XML tree\n",
    "import urllib\n",
    "import datetime\n",
    "import string\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------\n",
    "# Configuration data\n",
    "# ---------------\n",
    "\n",
    "graph_name = 'https://raw.githubusercontent.com/HeardLibrary/linked-data/54bd94c609e9c5af6c558cd926939ded67cba2ae/json_schema/bluffton_presidents.csv'\n",
    "accept_media_type = 'text/turtle'\n",
    "sparql_endpoint = \"https://sparql.vanderbilt.edu/sparql\"\n",
    "request_header_dictionary = {\n",
    "    #'Content-Type': 'application/sparql-query',\n",
    "    'Accept' : accept_media_type\n",
    "}\n",
    "\n",
    "# Load endpoint password from file in home directory\n",
    "directory = 'home'\n",
    "filename = 'sparql_vanderbilt_edu_password.txt'\n",
    "\n",
    "# ---------------\n",
    "# Function definitions\n",
    "# ---------------\n",
    "\n",
    "# Load password from local drive\n",
    "# value of directory should be either 'home' or 'working'\n",
    "def load_credential(filename, directory):\n",
    "    cred = ''\n",
    "    # to change the script to look for the credential in the working directory, change the value of home to empty string\n",
    "    if directory == 'home':\n",
    "        home = str(Path.home()) #gets path to home directory; supposed to work for Win and Mac\n",
    "        credential_path = home + '/' + filename\n",
    "    else:\n",
    "        directory = 'working'\n",
    "        credential_path = filename\n",
    "    try:\n",
    "        with open(credential_path, 'rt', encoding='utf-8') as file_object:\n",
    "            cred = file_object.read()\n",
    "    except:\n",
    "        print(filename + ' file not found - is it in your ' + directory + ' directory?')\n",
    "        exit()\n",
    "    return(cred)\n",
    "\n",
    "def retrieve_direct_statements(sparql_endpoint, graph_name):\n",
    "    query = '''\n",
    "construct {?item ?directProp ?value.}\n",
    "from <''' + graph_name + '''>\n",
    "where {\n",
    "  ?item ?p ?statement.\n",
    "  ?statement ?ps ?value.\n",
    "  filter(substr(str(?ps),1,39)=\"http://www.wikidata.org/prop/statement/\")\n",
    "  bind(substr(str(?ps),40) as ?id)\n",
    "  bind(substr(str(?p),30) as ?id)\n",
    "  bind(iri(concat(\"http://www.wikidata.org/prop/direct/\", ?id)) as ?directProp)\n",
    "  }\n",
    "'''\n",
    "    results = []\n",
    "    r = requests.get(sparql_endpoint, params={'query' : query}, headers=request_header_dictionary)\n",
    "    return r.text\n",
    "\n",
    "def retrieve_time_statements(sparql_endpoint, graph_name, subject_type):\n",
    "    # Happily, each subject type: \"statement\", \"reference\", and \"qualifier\" contains 9 characters.\n",
    "    # so the string extraction is the same for all.\n",
    "    query = '''\n",
    "prefix wikibase: <http://wikiba.se/ontology#>\n",
    "construct {?subject ?directProp ?timeValue.}\n",
    "from <''' + graph_name + '''>\n",
    "where {\n",
    "  ?subject ?valueProperty ?value.\n",
    "  ?value wikibase:timeValue ?timeValue.\n",
    "  filter(substr(str(?valueProperty),1,45)=\"http://www.wikidata.org/prop/''' + subject_type + '''/value/\")\n",
    "  bind(substr(str(?valueProperty),46) as ?id)\n",
    "  bind(iri(concat(\"http://www.wikidata.org/prop/''' + subject_type + '''/\", ?id)) as ?directProp)\n",
    "  }\n",
    "'''\n",
    "    results = []\n",
    "    r = requests.get(sparql_endpoint, params={'query' : query}, headers=request_header_dictionary)\n",
    "    return r.text\n",
    "\n",
    "def perform_sparql_update(sparql_endpoint, pwd, update_command):\n",
    "    # SPARQL Update requires HTTP POST\n",
    "    hdr = {'Content-Type' : 'application/sparql-update'}\n",
    "    r = requests.post(sparql_endpoint, auth=('admin', pwd), headers=hdr, data = update_command)\n",
    "    print(str(r.status_code) + ' ' + r.url)\n",
    "    print(r.text)\n",
    "\n",
    "def prep_and_update(sparql_endpoint, pwd, graph_name, graph_text):\n",
    "    # remove prefixes from response Turtle, which are not necessary since IRIs are unabbreviated\n",
    "    graph_text_list = graph_text.split('\\n')\n",
    "    # print(graph_text_list)\n",
    "    graph_text = ''\n",
    "    for line in graph_text_list:\n",
    "        try:\n",
    "            if line[0] != '@':\n",
    "                graph_text += line + '\\n'\n",
    "        except:\n",
    "            pass\n",
    "    #print()\n",
    "    #print(graph_text)\n",
    "\n",
    "    if len(graph_text) != 0: # don't perform an update if there aren't any triples to add\n",
    "        # Send SPARQL 1.1 UPDATE to endpoint to add the constructed triples into the graph\n",
    "        update_command = '''INSERT DATA\n",
    "        { GRAPH <''' + graph_name + '''> { \n",
    "        ''' + graph_text + '''\n",
    "        }}'''\n",
    "\n",
    "        #print(update_command)\n",
    "        perform_sparql_update(sparql_endpoint, pwd, update_command)\n",
    "    else:\n",
    "        print('no triples to write')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------\n",
    "# Construct the direct property statements entailed by the Wikibase model and retrieve from endpoint \n",
    "# ---------------\n",
    "pwd = load_credential(filename, directory)\n",
    "\n",
    "graph_text = retrieve_direct_statements(sparql_endpoint, graph_name)\n",
    "#print(graph_text)\n",
    "print('constructed direct triples retrieved')\n",
    "\n",
    "prep_and_update(sparql_endpoint, pwd, graph_name, graph_text)\n",
    "print()\n",
    "\n",
    "for subject_type in ['statement', 'reference', 'qualifier']:\n",
    "    graph_text = retrieve_time_statements(sparql_endpoint, graph_name, subject_type)\n",
    "    #print(graph_text)\n",
    "    print('constructed direct ' + subject_type + ' time triples retrieved')\n",
    "\n",
    "    prep_and_update(sparql_endpoint, pwd, graph_name, graph_text)\n",
    "    print()\n",
    "\n",
    "print()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
