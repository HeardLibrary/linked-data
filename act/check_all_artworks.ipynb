{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c) 2022 Vanderbilt University. This program is released under a GNU General Public License v3.0 http://www.gnu.org/licenses/gpl-3.0\n",
    "# Author: Steve Baskauf\n",
    "\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from time import sleep\n",
    "import json\n",
    "import urllib\n",
    "import csv\n",
    "import os\n",
    "from fuzzywuzzy import fuzz # fuzzy logic matching\n",
    "from copy import deepcopy\n",
    "from langdetect import detect\n",
    "from langdetect import detect_langs\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz # fuzzy logic matching\n",
    "\n",
    "# ----------------\n",
    "# Configuration settings\n",
    "# ----------------\n",
    "\n",
    "sparql_sleep = 0.1 # number of seconds to wait between queries to SPARQL endpoint\n",
    "get_server_sleep = 0.1 # number of seconds to wait before get calls to webserver\n",
    "dots_sleep = 1 # number of seconds to wait between calls to ParallelDots API\n",
    "home = str(Path.home()) # gets path to home directory; supposed to work for both Win and Mac\n",
    "endpoint = 'https://query.wikidata.org/sparql'\n",
    "accept_media_type = 'application/json'\n",
    "\n",
    "data_directory = '/Users/baskausj/vanderbilt/Digital Scholarship and Communications - Documents/data-curation/projects/wikidata/act/wikidata_data/'\n",
    "\n",
    "\n",
    "# Calculate the reference date retrieved value for all statements\n",
    "whole_time_string_z = datetime.datetime.utcnow().isoformat() # form: 2019-12-05T15:35:04.959311\n",
    "dateZ = whole_time_string_z.split('T')[0] # form 2019-12-05\n",
    "ref_retrieved = dateZ + 'T00:00:00Z' # form 2019-12-05T00:00:00Z as provided by Wikidata, without leading +\n",
    "\n",
    "def extract_qnumber(iri):\n",
    "    # pattern is http://www.wikidata.org/entity/Q6386232\n",
    "    pieces = iri.split('/')\n",
    "    return pieces[-1]\n",
    "\n",
    "# read from a CSV file into a list of dictionaries\n",
    "def read_dict(filename):\n",
    "    with open(filename, 'r', newline='', encoding='utf-8') as file_object:\n",
    "        dict_object = csv.DictReader(file_object)\n",
    "        array = []\n",
    "        for row in dict_object:\n",
    "            array.append(row)\n",
    "    return array\n",
    "\n",
    "# write a list of dictionaries to a CSV file\n",
    "def write_dicts_to_csv(table, filename, fieldnames):\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csv_file_object:\n",
    "        writer = csv.DictWriter(csv_file_object, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in table:\n",
    "            writer.writerow(row)\n",
    "\n",
    "def generate_header_dictionary(accept_media_type):\n",
    "    user_agent_header = 'DisambituateACT/0.1 (mailto:steve.baskauf@vanderbilt.edu)'\n",
    "    request_header_dictionary = {\n",
    "        'Accept' : accept_media_type,\n",
    "        'Content-Type': 'application/sparql-query',\n",
    "        'User-Agent': user_agent_header\n",
    "    }\n",
    "    return request_header_dictionary\n",
    "\n",
    "requestheader = generate_header_dictionary(accept_media_type)\n",
    "\n",
    "def retrieve_label(qid):\n",
    "    query = '''select distinct ?label where \n",
    "      {\n",
    "      wd:''' + qid + '''  wdt:P170 ?artist.\n",
    "      ?artist rdfs:label ?label.\n",
    "      filter(lang(?label) = 'en')\n",
    "      }'''\n",
    "\n",
    "    #print(query)\n",
    "\n",
    "    return_value = []\n",
    "    #print('sending query')\n",
    "    try:\n",
    "        r = requests.post(endpoint, data=query.encode('utf-8'), headers=generate_header_dictionary(accept_media_type))\n",
    "        #print('results returned')\n",
    "        data = r.json()\n",
    "    except:\n",
    "        print(r.text)\n",
    "        print('Failed query; waiting 10 seconds to try again.')\n",
    "        print()\n",
    "        sleep(10)\n",
    "        label = 'fail'\n",
    "    results = data['results']['bindings']\n",
    "    label = ''\n",
    "    try:\n",
    "        for result in results:\n",
    "            label = result['label']['value']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # delay a quarter second to avoid hitting the SPARQL endpoint too rapidly\n",
    "    sleep(sparql_sleep)\n",
    "    \n",
    "    return label\n",
    "\n",
    "def check_for_match(test_ratio, painting, act_id, act_title, act_artist):\n",
    "    result_dict = {}\n",
    "    ratio = fuzz.ratio(act_title, painting['label'])\n",
    "    #partial_ratio = fuzz.partial_ratio(act_title, painting['label'])\n",
    "    #sort_ratio = fuzz.token_sort_ratio(act_title, painting['label'])\n",
    "    #set_ratio = fuzz.token_set_ratio(act_title, painting['label'])\n",
    "    if ratio >= test_ratio:\n",
    "        qid = extract_qnumber(painting['item'])\n",
    "        wikidata_label = 'fail'\n",
    "        attempt = 0\n",
    "        while wikidata_label == 'fail' and attempt < 10:\n",
    "            attempt += 1\n",
    "            wikidata_label = retrieve_label(qid)\n",
    "        set_ratio = fuzz.token_set_ratio(act_artist, wikidata_label)\n",
    "        if set_ratio >= test_ratio:\n",
    "            print(ratio, painting['label'], ' / ', set_ratio, qid, wikidata_label)\n",
    "            result_dict['act_id'] = act_id\n",
    "            result_dict['act_title'] = act_title\n",
    "            result_dict['title_match'] = ratio\n",
    "            result_dict['qid'] = qid\n",
    "            result_dict['wikidata_label'] = painting['label']\n",
    "            result_dict['act_artist'] = act_artist\n",
    "            result_dict['artist_match'] = set_ratio\n",
    "            result_dict['wikidata_artist'] = wikidata_label\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "paintings_in_wikidata = pd.read_csv(data_directory + 'wikidata_paintings.csv', na_filter=False, dtype = str)\n",
    "paintings_in_wikidata.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonpaintings_in_wikidata = pd.read_csv(data_directory + 'wikidata_other_artwork_types.csv', na_filter=False, dtype = str)\n",
    "nonpaintings_in_wikidata.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "works_to_add = pd.read_csv('add_to_wikidata.csv', na_filter=False, dtype = str)\n",
    "works_to_add.set_index('act_id', inplace=True)\n",
    "#works_to_add = works_to_add.head(100) # use just the first 100 for testing\n",
    "works_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_data = pd.read_csv('../processed_lists/act_all_202109241353_repaired.csv', na_filter=False, dtype = str)\n",
    "act_data.set_index('RecordNumber', inplace=True)\n",
    "act_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test of fuzzy matching\n",
    "first = 'Lucas, van Leyden, 1494-1533'\n",
    "second = 'Lucas van Leyden'\n",
    "ratio = fuzz.ratio(first, second)\n",
    "partial_ratio = fuzz.partial_ratio(first, second)\n",
    "sort_ratio = fuzz.token_sort_ratio(first, second)\n",
    "set_ratio = fuzz.token_set_ratio(first, second)\n",
    "print('ratio', ratio)\n",
    "print('partial_ratio', partial_ratio)\n",
    "print('sort_ratio', sort_ratio)\n",
    "print('set_ratio', set_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use set ratio for artist name since it may be reversed, have dates, etc.\n",
    "test_ratio = 85\n",
    "\n",
    "output_list = []\n",
    "fieldnames = ['act_id', 'act_title', 'title_match', 'qid', 'wikidata_label', 'act_artist', 'artist_match', 'wikidata_artist']\n",
    "for act_id, work in works_to_add.iterrows():\n",
    "    print(act_id)\n",
    "    # look up informating from the ACT data file\n",
    "    try: # error trap in case there is a failure to match\n",
    "        act_title = act_data.loc[act_data.index == act_id, 'Title'].values[0]\n",
    "        act_artist = act_data.loc[act_data.index == act_id, 'CreatorArtist'].values[0]\n",
    "        act_type = act_data.loc[act_data.index == act_id, 'ObjectFunction'].values[0]\n",
    "    except:\n",
    "        continue # skip this work and go to the next one\n",
    "    print(act_title, '/', act_type, '/', act_artist)\n",
    "    if act_type == 'Painting':\n",
    "        for index, painting in paintings_in_wikidata.iterrows():\n",
    "            result_dict = check_for_match(test_ratio, painting, act_id, act_title, act_artist)\n",
    "            if result_dict != {}:\n",
    "                output_list.append(result_dict)\n",
    "                write_dicts_to_csv(output_list, 'artwork_matches.csv', fieldnames)\n",
    "                \n",
    "    elif act_type == '':\n",
    "        for index, painting in paintings_in_wikidata.iterrows():\n",
    "            result_dict = check_for_match(test_ratio, painting, act_id, act_title, act_artist)\n",
    "            if result_dict != {}:\n",
    "                output_list.append(result_dict)\n",
    "                write_dicts_to_csv(output_list, 'artwork_matches.csv', fieldnames)\n",
    "                \n",
    "        for index, nonpainting in nonpaintings_in_wikidata.iterrows():\n",
    "            result_dict = check_for_match(test_ratio, nonpainting, act_id, act_title, act_artist)\n",
    "            if result_dict != {}:\n",
    "                output_list.append(result_dict)\n",
    "                write_dicts_to_csv(output_list, 'artwork_matches.csv', fieldnames)\n",
    "                \n",
    "    else:\n",
    "        for index, nonpainting in nonpaintings_in_wikidata.iterrows():\n",
    "            result_dict = check_for_match(test_ratio, nonpainting, act_id, act_title, act_artist)\n",
    "            if result_dict != {}:\n",
    "                output_list.append(result_dict)\n",
    "                write_dicts_to_csv(output_list, 'artwork_matches.csv', fieldnames)\n",
    "                \n",
    "    print()\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
