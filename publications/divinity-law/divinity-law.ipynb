{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests   # best library to manage HTTP transactions\n",
    "from bs4 import BeautifulSoup # web-scraping library\n",
    "import json\n",
    "from time import sleep\n",
    "import csv\n",
    "import math\n",
    "from fuzzywuzzy import fuzz # fuzzy logic matching\n",
    "from fuzzywuzzy import process\n",
    "import xml.etree.ElementTree as et # library to traverse XML tree\n",
    "import urllib\n",
    "import datetime\n",
    "import string\n",
    "from pathlib import Path\n",
    "import copy # import the copy module from the standard library\n",
    "\n",
    "import vb_common_code as vbc\n",
    "\n",
    "employerQId = 'Q29052' # Vanderbilt University\n",
    "sparqlSleep = 0.1 # number of seconds to wait between queries to SPARQL endpoint\n",
    "testRatio = 90 # similarity required for a potential match of a generic wikidata match\n",
    "journalTestRatio = 94 # similarity required for a potential match of a generic wikidata match\n",
    "\n",
    "home = str(Path.home()) # gets path to home directory; supposed to work for both Win and Mac\n",
    "csv_path = home + '/divinity-law/vulibDivinity.csv'\n",
    "known_name_strings_path = home + '/divinity-law/known-name-strings.csv'\n",
    "journals_path = home + '/divinity-law/journals.csv'\n",
    "\n",
    "def reverse_names(nameLastFirst):\n",
    "    nameLastFirst = nameLastFirst.strip()\n",
    "    nameParts = nameLastFirst.split(',')\n",
    "    if len(nameParts) < 2: # name probably isn't reversed\n",
    "        name = nameLastFirst.strip()\n",
    "    else:\n",
    "        firstName = nameParts[1].strip()\n",
    "        lastName = nameParts[0].strip()\n",
    "        name = firstName + ' ' + lastName\n",
    "\n",
    "        if len(nameParts) > 2:\n",
    "            suffix = nameParts[2].strip()\n",
    "        else:\n",
    "            suffix = ''\n",
    "        name = firstName + ' ' + lastName\n",
    "        if suffix == 'Jr.':\n",
    "            name += ', Jr.'\n",
    "        elif suffix == 'Jr':\n",
    "            name += ', Jr.'\n",
    "        elif suffix == '':\n",
    "            pass\n",
    "        elif suffix == 'II':\n",
    "            name += ' ' + suffix\n",
    "        elif suffix == 'III':\n",
    "            name += ' ' + suffix\n",
    "        elif suffix == 'IV':\n",
    "            name += ' ' + suffix\n",
    "        elif suffix == 'V':\n",
    "            name += ' ' + suffix\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data from Zotero download CSV\n",
    "publications = vbc.readDict(csv_path)\n",
    "print(len(publications),'publications read from CSV')\n",
    "\n",
    "# read in previously discovered Q IDs and names\n",
    "known_name_strings = vbc.readDict(known_name_strings_path)\n",
    "print(len(known_name_strings),'discovered authors Q IDs read from CSV')\n",
    "\n",
    "# read in list of all Q IDs and names of journals in Wikidata\n",
    "journals_in_wikidata = vbc.readDict(journals_path)\n",
    "print(len(journals_in_wikidata),'journals read from CSV')\n",
    "\n",
    "# Download the labels and descriptions of all existing institutional people\n",
    "\n",
    "org_label_query = vbc.Query(labelscreen='?id wdt:P1416 ?deptOrCollege.?deptOrCollege wdt:P749+ wd:' + employerQId + '.', sleep=sparqlSleep)\n",
    "org_labels = org_label_query.labels_descriptions('')\n",
    "print(len(org_labels), 'labels downloaded')\n",
    "\n",
    "org_description_query = vbc.Query(labeltype='description', labelscreen='?id wdt:P1416 ?deptOrCollege.?deptOrCollege wdt:P749+ wd:' + employerQId + '.', sleep=sparqlSleep)\n",
    "org_descriptions = org_description_query.labels_descriptions('')\n",
    "print(len(org_descriptions), 'descriptions downloaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_list = []\n",
    "identified_authors_list = [] # list of dictionaries\n",
    "unidentified_authors_list = [] # list of strings\n",
    "identified_journals_list = [] # list of dictionaries\n",
    "unidentified_journals_list = [] # list of strings\n",
    "\n",
    "count = 0\n",
    "for publication in publications:\n",
    "    count += 1\n",
    "    # print something every 100 rows\n",
    "    if count % 100 == 0:\n",
    "        print(count)\n",
    "        \n",
    "    # Set up the output row by starting with the input row\n",
    "    # The input row is a dictionary\n",
    "    output_row = copy.deepcopy(publication) # use deepcopy rather than a reference\n",
    "        \n",
    "    # *********** Author matching ***********\n",
    "    \n",
    "    # First separate the authors if more than one\n",
    "    if ';' in publication['Author']:\n",
    "        names = publication['Author'].split(';')\n",
    "    else:\n",
    "        names = [publication['Author']]\n",
    "    names_list = []\n",
    "    \n",
    "    # Process each of the authors of the publication\n",
    "    for name in names:\n",
    "        # The name dict is where we store names and Q IDs (if discovered)\n",
    "        # for all of the authors of the paper\n",
    "        name_dictionary = {}\n",
    "        \n",
    "        # Guard against errors in the case where authors are missing\n",
    "        if name.strip() != '':\n",
    "            \n",
    "            # Neet to revers the names if they are last name first\n",
    "            name_string = reverse_names(name)\n",
    "            \n",
    "            # First check whether it's a name that matches a know Div School person\n",
    "            found = False\n",
    "            for label in org_labels:\n",
    "                # NOTE: used token_set_ratio here because of the wide variety of \n",
    "                # ways that names are sliced and diced. Need to determine how \n",
    "                # often there are false positives.\n",
    "                setRatio = fuzz.token_set_ratio(name_string, label['string'])\n",
    "                if setRatio >= testRatio: # We get a name match\n",
    "                    name_dictionary = label # Add the match to the name dict\n",
    "                    found = True\n",
    "                    matched = False\n",
    "                    \n",
    "                    # Find out whether we need to add to the list of IDed authors\n",
    "                    for id_name in identified_authors_list:\n",
    "                        if name_dictionary['string'] == id_name['string']:\n",
    "                            matched = True\n",
    "                            break\n",
    "                    if not matched:\n",
    "                        identified_authors_list.append(name_dictionary)\n",
    "                    break\n",
    "                    \n",
    "            # If the name loop wasn't broken, move on to checking the \n",
    "            # list we keep of identified people who don't match the VU list\n",
    "            for label in known_name_strings:\n",
    "                if name_string == label['string']: # We get a name match\n",
    "                    name_dictionary['qid'] = label['qid'] # Add the discoverd name\n",
    "                    name_dictionary['string'] = label['label'] # Add the discoverd label\n",
    "                    found = True\n",
    "                    matched = False\n",
    "                    \n",
    "                    # Find out whether we need to add this match to the list of IDed authors\n",
    "                    for id_name in identified_authors_list:\n",
    "                        if name_dictionary['string'] == id_name['string']:\n",
    "                            matched = True\n",
    "                            break\n",
    "                    if not matched:\n",
    "                        identified_authors_list.append(name_dictionary)\n",
    "                    break\n",
    "                \n",
    "            # If there is no match to either name source, then don't give a Q ID\n",
    "            if not found:\n",
    "                #print('none', name_string)\n",
    "                name_dictionary['qid'] = ''\n",
    "                name_dictionary['string'] = name_string\n",
    "                matched = False\n",
    "                \n",
    "                # Find out if this is a new unidentified name or \n",
    "                # if it's already on the list of unIDed people\n",
    "                for unid_name in unidentified_authors_list:\n",
    "                    if name_dictionary['string'] == unid_name:\n",
    "                        matched = True\n",
    "                        break\n",
    "                if not matched:\n",
    "                    unidentified_authors_list.append(name_dictionary['string'])\n",
    "            names_list.append(name_dictionary)\n",
    "    output_row['author_qids_names'] = names_list \n",
    "    #print(names_list)\n",
    "    \n",
    "    \n",
    "    # *********** Journal matching ***********\n",
    "\n",
    "    # only process rows for journal articles\n",
    "    if publication['Item Type'] == 'journalArticle':\n",
    "        # first see if the Publication Title is one we already know about\n",
    "        found_in_id_journals = False\n",
    "        for known_journal in identified_journals_list:\n",
    "            setRatio = fuzz.ratio(publication['Publication Title'], known_journal['label'])\n",
    "            if setRatio >= journalTestRatio: # We get a name match\n",
    "                found_in_id_journals = True\n",
    "                output_row['publication_title_qid'] = known_journal['qid'] # assign this Q ID for the journal of the row\n",
    "                # don't need to keep looking so quit the search loop\n",
    "                break\n",
    "                \n",
    "        # need to check the big list if the journal is new\n",
    "        if not found_in_id_journals:\n",
    "            found_in_poss_journals = False\n",
    "            for possible_journal in journals_in_wikidata:\n",
    "                # Used regular ratio rather than token_set_ratio here. There were false positives\n",
    "                # Due to the many similar journals that had overlapping name parts.\n",
    "                setRatio = fuzz.ratio(possible_journal['label'], publication['Publication Title'])\n",
    "                if setRatio >= journalTestRatio: # We get a title string match\n",
    "                    found_in_poss_journals = True\n",
    "                    output_row['publication_title_qid'] = possible_journal['qid'] # assign this Q ID for the journal of the row\n",
    "                    print(possible_journal['qid'], possible_journal['label'], setRatio, publication['Publication Title'])\n",
    "                    identified_journals_list.append({'qid': possible_journal['qid'], 'label': possible_journal['label']})\n",
    "                    break\n",
    "            if not found_in_poss_journals:\n",
    "                matched = False\n",
    "                for unid_journal in unidentified_journals_list:\n",
    "                    if publication['Publication Title'] == unid_journal:\n",
    "                        matched = True\n",
    "                        break\n",
    "                if not matched:\n",
    "                    unidentified_journals_list.append(publication['Publication Title'])\n",
    "    output_list.append(output_row)\n",
    "\n",
    "# Save the data\n",
    "filename = home + '/divinity-law/output.csv'\n",
    "fieldnames = ['author_qids_names', 'publication_title_qid'] + list(publications[0].keys())\n",
    "vbc.writeDictsToCsv(output_list, filename, fieldnames)\n",
    "\n",
    "# Save the identified authors\n",
    "filename = home + '/divinity-law/identified-authors.csv'\n",
    "fieldnames = ['qid', 'string']\n",
    "vbc.writeDictsToCsv(identified_authors_list, filename, fieldnames)\n",
    "\n",
    "# Save the identified journals\n",
    "filename = home + '/divinity-law/identified-journals.csv'\n",
    "fieldnames = ['qid', 'label']\n",
    "vbc.writeDictsToCsv(identified_journals_list, filename, fieldnames)\n",
    "\n",
    "# Save the list of unidentified authors\n",
    "filename = home + '/divinity-law/unidentified-authors.txt'\n",
    "with open(filename, 'wt', encoding='utf-8') as fileObject:\n",
    "    for author in unidentified_authors_list:\n",
    "        print(author, file=fileObject)\n",
    "\n",
    "# Save the list of unidentified journals\n",
    "filename = home + '/divinity-law/unidentified-journals.txt'\n",
    "with open(filename, 'wt', encoding='utf-8') as fileObject:\n",
    "    for journal in unidentified_journals_list:\n",
    "        print(journal, file=fileObject)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
