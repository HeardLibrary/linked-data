{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only once if you need to install the python-Levenshtein package\n",
    "\n",
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "statewide-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests   # best library to manage HTTP transactions\n",
    "#from bs4 import BeautifulSoup # web-scraping library\n",
    "import json\n",
    "from time import sleep\n",
    "import csv\n",
    "#import math\n",
    "#from fuzzywuzzy import fuzz # fuzzy logic matching\n",
    "#from fuzzywuzzy import process\n",
    "#import xml.etree.ElementTree as et # library to traverse XML tree\n",
    "import urllib\n",
    "#import datetime\n",
    "#import string\n",
    "\n",
    "accept_media_type = 'application/json'\n",
    "\n",
    "# Determine the current CrossRef rate limit by an initial ping\n",
    "crossref_headers = requests.get('https://api.crossref.org/works/10.3233/SW-150203', headers={'Accept' : accept_media_type}).headers\n",
    "limit_count = int(crossref_headers['x-rate-limit-limit'])\n",
    "interval_string = crossref_headers['x-rate-limit-interval']\n",
    "interval_sec = int(interval_string[:len(interval_string)-1]) # remove the \"s\" from the end\n",
    "api_sleep = interval_sec / limit_count + 0.005\n",
    "\n",
    "# generates a dictionary to be passed in a requests GET method to generate the request header\n",
    "def generate_header_dictionary(accept_media_type):\n",
    "    user_agent_header = 'VanderBot/1.7 (https://github.com/HeardLibrary/linked-data/tree/master/vanderbot; mailto:steve.baskauf@vanderbilt.edu)'\n",
    "    request_header_dictionary = {\n",
    "        'Accept' : accept_media_type,\n",
    "        'User-Agent': user_agent_header\n",
    "    }\n",
    "    return request_header_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "automotive-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://github.com/CrossRef/rest-api-doc for API details\n",
    "# Note: no authentication required, but must be \"nice\": observe rate limit, provide mailto:\n",
    "def retrieve_crossref_data(doi):\n",
    "    crossref_endpoint_url = 'https://api.crossref.org/works/'\n",
    "    # urllib.parse.quote performs URL encoding of a string\n",
    "    encoded_doi = urllib.parse.quote(doi)\n",
    "    search_url = crossref_endpoint_url + encoded_doi\n",
    "    response = requests.get(search_url, headers=generate_header_dictionary(accept_media_type))\n",
    "    article_dict = {}\n",
    "    if response.status_code != 404: # return empty dict if not found\n",
    "        author_list = []\n",
    "        try:\n",
    "            response_structure = response.json()\n",
    "            data = response_structure['message']\n",
    "        except:\n",
    "            # if not JSON, just return the response text\n",
    "            article_dict['message'] = response.text\n",
    "            sleep(api_sleep)\n",
    "            return article_dict\n",
    "        #print(json.dumps(data, indent = 2))\n",
    "        if 'author' in data:\n",
    "            authors = data['author']\n",
    "            for author in authors:\n",
    "                authorDict = {}\n",
    "                if 'ORCID' in author:\n",
    "                    authorDict['orcid'] = author['ORCID']\n",
    "                else:\n",
    "                    authorDict['orcid'] = ''\n",
    "                if 'sequence' in author:\n",
    "                    authorDict['sequence'] = author['sequence']\n",
    "                else:\n",
    "                    authorDict['sequence'] = ''\n",
    "                if 'given' in author:\n",
    "                    authorDict['givenName'] = author['given']\n",
    "                else:\n",
    "                    authorDict['givenName'] = ''\n",
    "                if 'family' in author:\n",
    "                    authorDict['familyName'] = author['family']\n",
    "                else:\n",
    "                    authorDict['familyName'] = ''\n",
    "                affiliationList = []\n",
    "                if 'affiliation' in author:\n",
    "                    for affiliation in author['affiliation']:\n",
    "                        affiliationList.append(affiliation['name'])\n",
    "                # if there aren't any affiliations, the list will remain empty\n",
    "                authorDict['affiliation'] = affiliationList\n",
    "                author_list.append(authorDict)\n",
    "            article_dict['authors'] = author_list\n",
    "        if 'issued' in data:\n",
    "            issued = data['issued']['date-parts'][0]\n",
    "            issued_date = str(issued[0])\n",
    "            if len(issued) > 1:\n",
    "                if len(str(issued[1])) == 1:\n",
    "                    issued_date += '-0'+ str(issued[1])\n",
    "                else:\n",
    "                    issued_date += '-'+ str(issued[1])\n",
    "                if len(issued) > 2:                \n",
    "                    if len(str(issued[2])) == 1:\n",
    "                        issued_date += '-0'+ str(issued[2])\n",
    "                    else:\n",
    "                        issued_date += '-'+ str(issued[2])\n",
    "            article_dict['issued'] = issued_date\n",
    "        else:\n",
    "            article_dict['issued'] = ''\n",
    "        if 'volume' in data:\n",
    "            article_dict['volume'] = data['volume']\n",
    "        else:\n",
    "            article_dict['volume'] = ''\n",
    "        if 'issue' in data:\n",
    "            article_dict['issue'] = data['issue']\n",
    "        else:\n",
    "            article_dict['issue'] = ''\n",
    "        if 'page' in data:\n",
    "            article_dict['pages'] = data['page']\n",
    "        else:\n",
    "            article_dict['pages'] = ''\n",
    "        if 'type' in data:\n",
    "            article_dict['type'] = data['type']\n",
    "        else:\n",
    "            article_dict['type'] = ''\n",
    "        if 'ISSN' in data:\n",
    "            article_dict['journal_issn'] = data['ISSN']\n",
    "        else:\n",
    "            article_dict['journal_issn'] = []\n",
    "        if 'container-title' in data:\n",
    "            article_dict['journal_title'] = data['container-title'][0]\n",
    "        else:\n",
    "            article_dict['journal_title'] = ''\n",
    "         \n",
    "    sleep(api_sleep)\n",
    "    return article_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dramatic-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "doi = '10.1186/S13643-020-01393-8'\n",
    "#doi = '10.1603/0046-225X-32.5.915'\n",
    "#doi = '10.3233/SW-150203'\n",
    "results = retrieve_crossref_data(doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cubic-dollar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"authors\": [\n",
      "    {\n",
      "      \"orcid\": \"http://orcid.org/0000-0003-2551-019X\",\n",
      "      \"sequence\": \"first\",\n",
      "      \"givenName\": \"Lori\",\n",
      "      \"familyName\": \"Schirle\",\n",
      "      \"affiliation\": []\n",
      "    },\n",
      "    {\n",
      "      \"orcid\": \"\",\n",
      "      \"sequence\": \"additional\",\n",
      "      \"givenName\": \"Amanda L.\",\n",
      "      \"familyName\": \"Stone\",\n",
      "      \"affiliation\": []\n",
      "    },\n",
      "    {\n",
      "      \"orcid\": \"\",\n",
      "      \"sequence\": \"additional\",\n",
      "      \"givenName\": \"Matthew C.\",\n",
      "      \"familyName\": \"Morris\",\n",
      "      \"affiliation\": []\n",
      "    },\n",
      "    {\n",
      "      \"orcid\": \"\",\n",
      "      \"sequence\": \"additional\",\n",
      "      \"givenName\": \"Sarah S.\",\n",
      "      \"familyName\": \"Osmundson\",\n",
      "      \"affiliation\": []\n",
      "    },\n",
      "    {\n",
      "      \"orcid\": \"\",\n",
      "      \"sequence\": \"additional\",\n",
      "      \"givenName\": \"Philip D.\",\n",
      "      \"familyName\": \"Walker\",\n",
      "      \"affiliation\": []\n",
      "    },\n",
      "    {\n",
      "      \"orcid\": \"\",\n",
      "      \"sequence\": \"additional\",\n",
      "      \"givenName\": \"Mary S.\",\n",
      "      \"familyName\": \"Dietrich\",\n",
      "      \"affiliation\": []\n",
      "    },\n",
      "    {\n",
      "      \"orcid\": \"\",\n",
      "      \"sequence\": \"additional\",\n",
      "      \"givenName\": \"Stephen\",\n",
      "      \"familyName\": \"Bruehl\",\n",
      "      \"affiliation\": []\n",
      "    }\n",
      "  ],\n",
      "  \"issued\": \"2020-06-11\",\n",
      "  \"volume\": \"9\",\n",
      "  \"issue\": \"1\",\n",
      "  \"pages\": \"\",\n",
      "  \"type\": \"journal-article\",\n",
      "  \"journal_issn\": [\n",
      "    \"2046-4053\"\n",
      "  ],\n",
      "  \"journal_title\": \"Systematic Reviews\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
