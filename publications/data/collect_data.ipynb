{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import, configuration, functions, etc.\n",
    "# Run this every time you use the script\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from time import sleep\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "sparqlSleep = 0.1 # number of seconds to wait between queries to SPARQL endpoint\n",
    "\n",
    "def generateHeaderDictionary(acceptMediaType):\n",
    "    userAgentHeader = 'VanderBot/1.0 (https://github.com/HeardLibrary/linked-data/tree/master/publications; mailto:steve.baskauf@vanderbilt.edu)'\n",
    "    requestHeaderDictionary = {\n",
    "        'Accept' : acceptMediaType,\n",
    "        'User-Agent': userAgentHeader\n",
    "    }\n",
    "    return requestHeaderDictionary\n",
    "\n",
    "def generate_utc_date():\n",
    "    wholeTimeStringZ = datetime.datetime.utcnow().isoformat() # form: 2019-12-05T15:35:04.959311\n",
    "    dateZ = wholeTimeStringZ.split('T')[0] # form 2019-12-05\n",
    "    return dateZ\n",
    "\n",
    "# extracts the qNumber from a Wikidata IRI\n",
    "def extract_qnumber(iri):\n",
    "    # pattern is http://www.wikidata.org/entity/Q6386232\n",
    "    pieces = iri.split('/')\n",
    "    return pieces[4]\n",
    "\n",
    "# write a list of lists to a CSV file\n",
    "def writeListsToCsv(fileName, array):\n",
    "    with open(fileName, 'w', newline='', encoding='utf-8') as fileObject:\n",
    "        writerObject = csv.writer(fileObject)\n",
    "        for row in array:\n",
    "            writerObject.writerow(row)\n",
    "\n",
    "\n",
    "def read_lists_from_csv(filename):\n",
    "    with open(filename, 'r', newline='', encoding='utf-8') as file_object:\n",
    "        reader_object = csv.reader(file_object)\n",
    "        list_of_lists = []\n",
    "        for row_list in reader_object:\n",
    "            list_of_lists.append(row_list)\n",
    "    return list_of_lists\n",
    "\n",
    "\n",
    "            # write a list of dictionaries to a CSV file\n",
    "def writeDictsToCsv(table, filename, fieldnames):\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvFileObject:\n",
    "        writer = csv.DictWriter(csvFileObject, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in table:\n",
    "            writer.writerow(row)\n",
    "\n",
    "            # read from a CSV file into a list of dictionaries\n",
    "def readDict(filename):\n",
    "    with open(filename, 'r', newline='', encoding='utf-8') as fileObject:\n",
    "        dictObject = csv.DictReader(fileObject)\n",
    "        array = []\n",
    "        for row in dictObject:\n",
    "            array.append(row)\n",
    "    return array\n",
    "\n",
    "def get_vu_counts(query):\n",
    "    wikidataEndpointUrl = 'https://query.wikidata.org/sparql'\n",
    "    acceptMediaType = 'application/json'\n",
    "    r = requests.get(wikidataEndpointUrl, params={'query' : query}, headers = generateHeaderDictionary(acceptMediaType))\n",
    "    try:\n",
    "        data = r.json()\n",
    "        #print(json.dumps(data, indent=2))\n",
    "        count = data['results']['bindings'][0]['count']['value']\n",
    "    except:\n",
    "        count = [r.text]\n",
    "    # delay to avoid hitting the SPARQL endpoint to rapidly\n",
    "    sleep(sparqlSleep)\n",
    "    return count\n",
    "\n",
    "def get_unit_counts(query):\n",
    "    table = []\n",
    "    wikidataEndpointUrl = 'https://query.wikidata.org/sparql'\n",
    "    acceptMediaType = 'application/json'\n",
    "    r = requests.get(wikidataEndpointUrl, params={'query' : query}, headers = generateHeaderDictionary(acceptMediaType))\n",
    "    try:\n",
    "        data = r.json()\n",
    "        statements = data['results']['bindings']\n",
    "        for statement in statements:\n",
    "            unit_iri = statement['unit']['value']\n",
    "            unit_qnumber = extract_qnumber(unit_iri)\n",
    "            count = statement['count']['value']\n",
    "            table.append({'unit': unit_qnumber, 'count': count})\n",
    "    except:\n",
    "        table = [r.text]\n",
    "    # delay to avoid hitting the SPARQL endpoint to rapidly\n",
    "    sleep(sparqlSleep)\n",
    "    return table\n",
    "\n",
    "def add_query_to_vu_table(filename, query):\n",
    "    table = read_lists_from_csv(filename)\n",
    "    #print(table)\n",
    "\n",
    "    count = get_vu_counts(query)\n",
    "    #print(count)\n",
    "    \n",
    "    date = generate_utc_date()\n",
    "    row_list = [date]\n",
    "    row_list.append(count)\n",
    "    #print(row_list)\n",
    "    table.append(row_list)\n",
    "    #print(table)\n",
    "\n",
    "    writeListsToCsv(filename, table)\n",
    "\n",
    "def add_query_to_unit_table(filename, query):\n",
    "    table = read_lists_from_csv(filename)\n",
    "    #print(table)\n",
    "\n",
    "    dictionary = get_unit_counts(query)\n",
    "    #print(json.dumps(dictionary, indent=2))\n",
    "    \n",
    "    date = generate_utc_date()\n",
    "    row_list = [date]\n",
    "    for header in table[0][1:len(table[0])]: # skip the first item (date)\n",
    "        found = False\n",
    "        for count in dictionary:\n",
    "            if count['unit'] == header:\n",
    "                found = True\n",
    "                row_list.append(count['count'])\n",
    "        if not found:\n",
    "            row_list.append('0')\n",
    "    #print(row_list)\n",
    "    table.append(row_list)\n",
    "\n",
    "    writeListsToCsv(filename, table)\n",
    "    \n",
    "def run_all_queries():\n",
    "    # -----------------------------\n",
    "    # Queries for all of Vanderbilt\n",
    "    # -----------------------------\n",
    "\n",
    "    # query to get the total number of persons affiliated with Vanderbilt units\n",
    "    query = '''\n",
    "    select (count(distinct ?person) as ?count)  where {\n",
    "      ?unit wdt:P749+ wd:Q29052.\n",
    "      ?person wdt:P1416 ?unit.\n",
    "      }\n",
    "    '''\n",
    "    filename = 'vu_total.csv'\n",
    "    add_query_to_vu_table(filename, query)\n",
    "    print(filename)\n",
    "\n",
    "    # query to get the total number of men affiliated with Vanderbilt units\n",
    "    query = '''\n",
    "    select (count(distinct ?man) as ?count)  where {\n",
    "      ?unit wdt:P749+ wd:Q29052.\n",
    "      ?man wdt:P1416 ?unit.\n",
    "      ?man wdt:P21 wd:Q6581097.\n",
    "      }\n",
    "    '''\n",
    "    filename = 'vu_men.csv'\n",
    "    add_query_to_vu_table(filename, query)\n",
    "    print(filename)\n",
    "\n",
    "    # query to get the total number of women affiliated with Vanderbilt units\n",
    "    query = '''\n",
    "    select (count(distinct ?woman) as ?count)  where {\n",
    "      ?unit wdt:P749+ wd:Q29052.\n",
    "      ?woman wdt:P1416 ?unit.\n",
    "      ?woman wdt:P21 wd:Q6581072.\n",
    "      }\n",
    "    '''\n",
    "    filename = 'vu_women.csv'\n",
    "    add_query_to_vu_table(filename, query)\n",
    "    print(filename)\n",
    "\n",
    "    # query to count number of people with ORCIDs\n",
    "    query = '''\n",
    "    select (count(distinct ?person) as ?count)  where {\n",
    "      ?unit wdt:P749+ wd:Q29052.\n",
    "      ?person wdt:P1416 ?unit.\n",
    "      ?person wdt:P496 ?orcid.\n",
    "      }\n",
    "    '''\n",
    "    filename = 'vu_orcid.csv'\n",
    "    add_query_to_vu_table(filename, query)\n",
    "    print(filename)\n",
    "    \n",
    "    # query to get the total number works authored by anyone affiliated with Vanderbilt units\n",
    "    query = '''\n",
    "    select (count(distinct ?work) as ?count)  where {\n",
    "      ?unit wdt:P749+ wd:Q29052.\n",
    "      ?person wdt:P1416 ?unit.\n",
    "      ?work wdt:P50 ?person.\n",
    "      }\n",
    "    '''\n",
    "    filename = 'vu_works.csv'\n",
    "    add_query_to_vu_table(filename, query)\n",
    "    print(filename)\n",
    "\n",
    "    # query to get the total number works authored by men affiliated with Vanderbilt units\n",
    "    query = '''\n",
    "    select (count(distinct ?work) as ?count)  where {\n",
    "      ?unit wdt:P749+ wd:Q29052.\n",
    "      ?man wdt:P1416 ?unit.\n",
    "      ?man wdt:P21 wd:Q6581097.\n",
    "      ?work wdt:P50 ?man.\n",
    "      }\n",
    "    '''\n",
    "    filename = 'vu_men_works.csv'\n",
    "    add_query_to_vu_table(filename, query)\n",
    "    print(filename)\n",
    "\n",
    "    # query to get the total number works authored by women affiliated with Vanderbilt units\n",
    "    query = '''\n",
    "    select (count(distinct ?work) as ?count)  where {\n",
    "      ?unit wdt:P749+ wd:Q29052.\n",
    "      ?woman wdt:P1416 ?unit.\n",
    "      ?woman wdt:P21 wd:Q6581072.\n",
    "      ?work wdt:P50 ?woman.\n",
    "      }\n",
    "    '''\n",
    "    filename = 'vu_women_works.csv'\n",
    "    add_query_to_vu_table(filename, query)\n",
    "    print(filename)\n",
    "\n",
    "\n",
    "\n",
    "    # ------------------------\n",
    "    # Query by Vanderbilt unit\n",
    "    # ------------------------\n",
    "\n",
    "    # query to get the total number of persons affiliated with each unit\n",
    "    query = '''\n",
    "    select ?unit (count(distinct ?person) as ?count)  where {\n",
    "      ?unit wdt:P749+ wd:Q29052.\n",
    "      ?person wdt:P1416 ?unit.\n",
    "      }\n",
    "    group by ?unit\n",
    "    '''\n",
    "    filename = 'units_total.csv'\n",
    "    add_query_to_unit_table(filename, query)\n",
    "    print(filename)\n",
    "\n",
    "    # query to get the total number of women affiliated with each unit\n",
    "    query = '''\n",
    "    select ?unit (count(distinct ?woman) as ?count)  where {\n",
    "      ?unit wdt:P749+ wd:Q29052.\n",
    "      ?woman wdt:P1416 ?unit.\n",
    "      ?woman wdt:P21 wd:Q6581072.\n",
    "      }\n",
    "    group by ?unit\n",
    "    '''\n",
    "    filename = 'units_women.csv'\n",
    "    add_query_to_unit_table(filename, query)\n",
    "    print(filename)\n",
    "\n",
    "    # query to get the total number of men affiliated with each unit\n",
    "    query = '''\n",
    "    select ?unit (count(distinct ?man) as ?count)  where {\n",
    "      ?unit wdt:P749+ wd:Q29052.\n",
    "      ?man wdt:P1416 ?unit.\n",
    "      ?man wdt:P21 wd:Q6581097.\n",
    "      }\n",
    "    group by ?unit\n",
    "    '''\n",
    "    filename = 'units_men.csv'\n",
    "    add_query_to_unit_table(filename, query)\n",
    "    print(filename)\n",
    "\n",
    "    # query to get the total number of people having ORCIDs affiliated with each unit\n",
    "    query = '''\n",
    "    select ?unit (count(distinct ?person) as ?count)  where {\n",
    "      ?unit wdt:P749+ wd:Q29052.\n",
    "      ?person wdt:P1416 ?unit.\n",
    "      ?person wdt:P496 ?orcid.\n",
    "      }\n",
    "    group by ?unit\n",
    "    '''\n",
    "    filename = 'units_orcid.csv'\n",
    "    add_query_to_unit_table(filename, query)\n",
    "    print(filename)\n",
    "\n",
    "    # query to get the total number of authored works associated with each unit\n",
    "    query = '''\n",
    "    select ?unit (count(distinct ?work) as ?count)  where {\n",
    "      ?unit wdt:P749+ wd:Q29052.\n",
    "      ?person wdt:P1416 ?unit.\n",
    "      ?work wdt:P50 ?person.\n",
    "      }\n",
    "    group by ?unit\n",
    "    '''\n",
    "    filename = 'units_works.csv'\n",
    "    add_query_to_unit_table(filename, query)\n",
    "    print(filename)\n",
    "\n",
    "    # query to get the total number of authored works by men affiliated with each unit\n",
    "    query = '''\n",
    "    select ?unit (count(distinct ?work) as ?count)  where {\n",
    "      ?unit wdt:P749+ wd:Q29052.\n",
    "      ?man wdt:P1416 ?unit.\n",
    "      ?man wdt:P21 wd:Q6581097.\n",
    "      ?work wdt:P50 ?man.\n",
    "      }\n",
    "    group by ?unit\n",
    "    '''\n",
    "    filename = 'units_works_men.csv'\n",
    "    add_query_to_unit_table(filename, query)\n",
    "    print(filename)\n",
    "\n",
    "    # query to get the total number of authored works by women affiliated with each unit\n",
    "    query = '''\n",
    "    select ?unit (count(distinct ?work) as ?count)  where {\n",
    "      ?unit wdt:P749+ wd:Q29052.\n",
    "      ?woman wdt:P1416 ?unit.\n",
    "      ?woman wdt:P21 wd:Q6581072.\n",
    "      ?work wdt:P50 ?woman.\n",
    "      }\n",
    "    group by ?unit\n",
    "    '''\n",
    "    filename = 'units_works_women.csv'\n",
    "    add_query_to_unit_table(filename, query)\n",
    "    print(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# ---------------\n",
    "# Run this once the first time you set up\n",
    "# !!! Running it again will wipe out all of your data !!!\n",
    "# ---------------\n",
    "\n",
    "# Get the Wikidata IDs and names for Vanderbilt Units\n",
    "\n",
    "# create a string for the query\n",
    "query = '''\n",
    "select ?label ?unit ?parent where {\n",
    "  ?unit wdt:P749+ wd:Q29052.  # Q29052 is Vanderbilt\n",
    "  ?unit wdt:P749 ?parent.\n",
    "  ?unit rdfs:label ?label.\n",
    "  filter(lang(?label) = 'en')\n",
    "  }\n",
    "order by ?label\n",
    "'''\n",
    "\n",
    "#print(query)\n",
    "\n",
    "unit_table = []\n",
    "wikidataEndpointUrl = 'https://query.wikidata.org/sparql'\n",
    "acceptMediaType = 'application/json'\n",
    "r = requests.get(wikidataEndpointUrl, params={'query' : query}, headers = generateHeaderDictionary(acceptMediaType))\n",
    "try:\n",
    "    data = r.json()\n",
    "    statements = data['results']['bindings']\n",
    "    for statement in statements:\n",
    "        unit_iri = statement['unit']['value']\n",
    "        unit_qnumber = extract_qnumber(unit_iri)\n",
    "        parent_iri = statement['parent']['value']\n",
    "        parent_qnumber = extract_qnumber(parent_iri)\n",
    "        unit_label = statement['label']['value']\n",
    "        unit_table.append({'unit': unit_qnumber, 'label': unit_label, 'parent': parent_qnumber})\n",
    "except:\n",
    "    unit_table = [r.text]\n",
    "# delay a quarter second to avoid hitting the SPARQL endpoint to rapidly\n",
    "#sleep(sparqlSleep)\n",
    "\n",
    "#print(json.dumps(unit_table, indent=2))\n",
    "\n",
    "writeDictsToCsv(unit_table, 'vanderbilt_units.csv', ['unit', 'label', 'parent'])\n",
    "\n",
    "\n",
    "# create blank files for institution-wide data\n",
    "\n",
    "unit_files = ['vu_total.csv', 'vu_men.csv', 'vu_works.csv', 'vu_women.csv', 'vu_orcid.csv', 'vu_men_works.csv', 'vu_women_works.csv']\n",
    "\n",
    "for file_name in unit_files:\n",
    "    header_row = ['date', 'count']\n",
    "    header_table = [header_row]\n",
    "    writeListsToCsv(file_name, header_table)\n",
    "\n",
    "# create blank files for units data\n",
    "\n",
    "unit_files = ['units_total.csv', 'units_women.csv', 'units_men.csv', 'units_orcid.csv', 'units_works.csv', 'units_works_men.csv', 'units_works_women.csv']\n",
    "\n",
    "for file_name in unit_files:\n",
    "    header_row = ['date']\n",
    "    for unit in unit_table:\n",
    "        header_row.append(unit['unit'])\n",
    "    header_table = [header_row]\n",
    "    writeListsToCsv(file_name, header_table)\n",
    "    \n",
    "# Write date when last run\n",
    "with open('last_run.txt', 'wt', encoding='utf-8') as fileObject:\n",
    "    fileObject.write(generate_utc_date())\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time checked: 2020-05-08T01:49:31.391014\n",
      "Date last run: 2020-05-07\n",
      "UTC date now is: 2020-05-08\n",
      "vu_total.csv\n",
      "vu_men.csv\n",
      "vu_women.csv\n",
      "vu_orcid.csv\n",
      "vu_works.csv\n",
      "vu_men_works.csv\n",
      "vu_women_works.csv\n",
      "units_total.csv\n",
      "units_women.csv\n",
      "units_men.csv\n",
      "units_orcid.csv\n",
      "units_works.csv\n",
      "units_works_men.csv\n",
      "units_works_women.csv\n",
      "done\n",
      "\n",
      "Time checked: 2020-05-08T02:49:41.157636\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T03:49:41.284151\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T04:49:41.370765\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T05:49:41.465907\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T06:49:41.549402\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T07:49:41.629646\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T08:49:41.719537\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T09:49:41.807467\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T10:49:41.898489\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T11:49:42.012110\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T12:49:42.109030\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T13:49:42.197187\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T14:49:42.300108\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T15:49:42.422633\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T16:49:42.495199\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T17:49:42.573137\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T18:49:42.661566\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T19:49:42.757022\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T20:49:42.847905\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T21:49:42.951203\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T22:49:43.055988\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-08T23:49:43.143104\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-08\n",
      "\n",
      "Time checked: 2020-05-09T00:49:43.224618\n",
      "Date last run: 2020-05-08\n",
      "UTC date now is: 2020-05-09\n",
      "vu_total.csv\n",
      "vu_men.csv\n",
      "vu_women.csv\n",
      "vu_orcid.csv\n",
      "vu_works.csv\n",
      "vu_men_works.csv\n",
      "vu_women_works.csv\n",
      "units_total.csv\n",
      "units_women.csv\n",
      "units_men.csv\n",
      "units_orcid.csv\n",
      "units_works.csv\n",
      "units_works_men.csv\n",
      "units_works_women.csv\n",
      "done\n",
      "\n",
      "Time checked: 2020-05-09T01:49:51.345001\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T02:49:51.439075\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T03:49:51.536110\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T04:49:51.625600\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T05:49:51.709134\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T06:49:51.803169\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T07:49:51.888826\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T08:49:51.968071\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T09:49:52.056129\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T10:49:52.139157\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T11:49:52.228397\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T12:49:52.357975\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T13:49:52.458515\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T14:49:52.544262\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T15:49:52.634099\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T16:49:52.724176\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T17:49:52.812659\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T18:49:52.896096\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T19:49:52.988897\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T20:49:53.076401\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T21:49:53.172570\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T22:49:53.266923\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-09T23:49:53.366437\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-09\n",
      "\n",
      "Time checked: 2020-05-10T00:49:53.446834\n",
      "Date last run: 2020-05-09\n",
      "UTC date now is: 2020-05-10\n",
      "vu_total.csv\n",
      "vu_men.csv\n",
      "vu_women.csv\n",
      "vu_orcid.csv\n",
      "vu_works.csv\n",
      "vu_men_works.csv\n",
      "vu_women_works.csv\n",
      "units_total.csv\n",
      "units_women.csv\n",
      "units_men.csv\n",
      "units_orcid.csv\n",
      "units_works.csv\n",
      "units_works_men.csv\n",
      "units_works_women.csv\n",
      "done\n",
      "\n",
      "Time checked: 2020-05-10T01:50:03.718481\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T02:50:03.814329\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T03:50:03.903801\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T04:50:03.989187\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T05:50:04.096415\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T06:50:04.187339\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T07:50:04.262833\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T08:50:04.342017\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T09:50:04.435148\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T10:50:04.510156\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T11:50:04.595303\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T12:50:04.677113\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T13:50:04.763222\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T14:50:04.850564\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T15:50:04.934653\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T16:50:05.017712\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T17:50:05.108705\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T18:50:05.195463\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T19:50:05.291901\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T20:50:05.370312\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T21:50:05.446149\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T22:50:05.512759\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-10T23:50:05.617869\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-10\n",
      "\n",
      "Time checked: 2020-05-11T00:50:05.712048\n",
      "Date last run: 2020-05-10\n",
      "UTC date now is: 2020-05-11\n",
      "vu_total.csv\n",
      "vu_men.csv\n",
      "vu_women.csv\n",
      "vu_orcid.csv\n",
      "vu_works.csv\n",
      "vu_men_works.csv\n",
      "vu_women_works.csv\n",
      "units_total.csv\n",
      "units_women.csv\n",
      "units_men.csv\n",
      "units_orcid.csv\n",
      "units_works.csv\n",
      "units_works_men.csv\n",
      "units_works_women.csv\n",
      "done\n",
      "\n",
      "Time checked: 2020-05-11T01:50:18.104958\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T02:50:18.193444\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T03:50:18.281000\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T04:50:18.377813\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T05:50:18.470745\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time checked: 2020-05-11T06:50:18.540706\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T07:50:18.621453\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T08:50:18.717222\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T09:50:18.800221\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T10:50:18.886589\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T11:50:18.978191\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T12:50:19.086860\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T13:50:19.181051\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T14:50:19.268918\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T15:50:19.361441\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T16:50:19.450397\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T17:50:19.538420\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T18:50:19.611671\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T19:50:19.712093\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T20:50:19.803044\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T21:50:19.889138\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T22:50:19.971218\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-11T23:50:20.069007\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-11\n",
      "\n",
      "Time checked: 2020-05-12T00:50:20.148518\n",
      "Date last run: 2020-05-11\n",
      "UTC date now is: 2020-05-12\n",
      "vu_total.csv\n",
      "vu_men.csv\n",
      "vu_women.csv\n",
      "vu_orcid.csv\n",
      "vu_works.csv\n",
      "vu_men_works.csv\n",
      "vu_women_works.csv\n",
      "units_total.csv\n",
      "units_women.csv\n",
      "units_men.csv\n",
      "units_orcid.csv\n",
      "units_works.csv\n",
      "units_works_men.csv\n",
      "units_works_women.csv\n",
      "done\n",
      "\n",
      "Time checked: 2020-05-12T01:50:36.605806\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T02:50:36.699725\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T03:50:36.796413\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T04:50:36.883084\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T05:50:36.973614\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T06:50:37.062071\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T07:50:37.146687\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T08:50:37.221154\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T09:50:37.307779\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T10:50:37.399049\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T11:50:37.525346\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T12:50:37.615471\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T13:50:37.696909\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T14:50:37.782183\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T15:50:37.874209\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T16:50:37.962941\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T17:50:38.062403\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T18:50:38.154956\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T19:50:38.243875\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T20:50:38.322631\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T21:50:38.437034\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T22:50:38.521246\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-12T23:50:38.613196\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-12\n",
      "\n",
      "Time checked: 2020-05-13T00:50:38.708732\n",
      "Date last run: 2020-05-12\n",
      "UTC date now is: 2020-05-13\n",
      "vu_total.csv\n",
      "vu_men.csv\n",
      "vu_women.csv\n",
      "vu_orcid.csv\n",
      "vu_works.csv\n",
      "vu_men_works.csv\n",
      "vu_women_works.csv\n",
      "units_total.csv\n",
      "units_women.csv\n",
      "units_men.csv\n",
      "units_orcid.csv\n",
      "units_works.csv\n",
      "units_works_men.csv\n",
      "units_works_women.csv\n",
      "done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Script to actually collect the data\n",
    "\n",
    "#data = readDict('vanderbilt_units.csv')\n",
    "#print(json.dumps(data,indent=2))\n",
    "\n",
    "while True: # infinite loop\n",
    "    print('Time checked:', datetime.datetime.utcnow().isoformat())\n",
    "    with open('last_run.txt', 'rt', encoding='utf-8') as fileObject:\n",
    "        date_last_run = fileObject.read()\n",
    "    print('Date last run:', date_last_run)\n",
    "\n",
    "    date_now_utc = generate_utc_date()\n",
    "    print('UTC date now is:', date_now_utc)\n",
    "\n",
    "    if date_now_utc > date_last_run:\n",
    "        run_all_queries()\n",
    "\n",
    "        # Update the date last run\n",
    "        with open('last_run.txt', 'wt', encoding='utf-8') as fileObject:\n",
    "            fileObject.write(generate_utc_date())\n",
    "\n",
    "        print('done')\n",
    "    print()\n",
    "\n",
    "    # wait an hour before checking again\n",
    "    sleep(3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
