{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import requests\n",
    "import csv\n",
    "import json\n",
    "from time import sleep\n",
    "\n",
    "def readDict(filename):\n",
    "    fileObject = open(filename, 'r', newline='', encoding='utf-8')\n",
    "    dictObject = csv.DictReader(fileObject)\n",
    "    array = []\n",
    "    for row in dictObject:\n",
    "        array.append(row)\n",
    "    fileObject.close()\n",
    "    return array\n",
    "\n",
    "def extractQNumber(iri):\n",
    "    # pattern is http://www.wikidata.org/entity/Q6386232\n",
    "    pieces = iri.split('/')\n",
    "    return pieces[4]\n",
    "\n",
    "# query for a single variable that's an item named 'item'\n",
    "# returns a list of results\n",
    "def searchWikidataForQId(query):\n",
    "    results = []\n",
    "    endpointUrl = 'https://query.wikidata.org/sparql'\n",
    "    acceptMediaType = 'application/json'\n",
    "    userAgentHeader = 'BaskaufScraper/0.1 (steve.baskauf@vanderbilt.edu)'\n",
    "    requestHeaderDictionary = {\n",
    "    'Accept' : acceptMediaType,\n",
    "    'User-Agent': userAgentHeader\n",
    "}\n",
    "    r = requests.get(endpointUrl, params={'query' : query}, headers=requestHeaderDictionary)\n",
    "    try:\n",
    "        data = r.json()\n",
    "        statements = data['results']['bindings']\n",
    "        for statement in statements:\n",
    "            wikidataIri = statement['item']['value']\n",
    "            qNumber = extractQNumber(wikidataIri)\n",
    "            results.append(qNumber)\n",
    "    except:\n",
    "        results = [r.text]\n",
    "    # delay a quarter second to avoid hitting the SPARQL endpoint to rapidly\n",
    "    sleep(0.25)\n",
    "    return results\n",
    "\n",
    "def generateNameAlternatives(name):\n",
    "    # get rid of periods\n",
    "    name = name.replace('.', '')\n",
    "    pieces = name.split(' ')\n",
    "    \n",
    "    # generate initials for all names\n",
    "    initials = []\n",
    "    for piece in pieces:\n",
    "        initials.append(piece[0:1])\n",
    "        \n",
    "    alternatives = []\n",
    "    # full name\n",
    "    nameVersion = ''\n",
    "    for pieceNumber in range(0, len(pieces)-1):\n",
    "        nameVersion += pieces[pieceNumber] + ' '\n",
    "    nameVersion += pieces[len(pieces)-1]\n",
    "    alternatives.append(nameVersion)\n",
    "    \n",
    "    # first and last name with initials\n",
    "    nameVersion = pieces[0] + ' '\n",
    "    for pieceNumber in range(1, len(pieces)-1):\n",
    "        nameVersion += initials[pieceNumber] + ' '\n",
    "    nameVersion += pieces[len(pieces)-1]\n",
    "    alternatives.append(nameVersion)\n",
    "    \n",
    "    # first and last name with initials and periods\n",
    "    nameVersion = pieces[0] + ' '\n",
    "    for pieceNumber in range(1, len(pieces)-1):\n",
    "        nameVersion += initials[pieceNumber] + '. '\n",
    "    nameVersion += pieces[len(pieces)-1]\n",
    "    alternatives.append(nameVersion)\n",
    "\n",
    "    # first and last name only\n",
    "    nameVersion = pieces[0] + ' '\n",
    "    nameVersion += pieces[len(pieces)-1]\n",
    "    alternatives.append(nameVersion)\n",
    "\n",
    "    # first initial and last name only\n",
    "    nameVersion = initials[0] + ' '\n",
    "    nameVersion += pieces[len(pieces)-1]\n",
    "    alternatives.append(nameVersion)\n",
    "\n",
    "    # first initial with period and last name only\n",
    "    nameVersion = initials[0] + '. '\n",
    "    nameVersion += pieces[len(pieces)-1]\n",
    "    alternatives.append(nameVersion)\n",
    "\n",
    "    # all name initials with last name\n",
    "    nameVersion = initials[0] + ' '\n",
    "    for pieceNumber in range(1, len(pieces)-1):\n",
    "        nameVersion += initials[pieceNumber] + ' '\n",
    "    nameVersion += pieces[len(pieces)-1]\n",
    "    alternatives.append(nameVersion)\n",
    "\n",
    "    # all name initials with periods with last name\n",
    "    nameVersion = ''\n",
    "    for pieceNumber in range(0, len(pieces)-1):\n",
    "        nameVersion += initials[pieceNumber] + '. '\n",
    "    nameVersion += pieces[len(pieces)-1]\n",
    "    alternatives.append(nameVersion)\n",
    "\n",
    "    # all name initials concatenated with last name\n",
    "    nameVersion = ''\n",
    "    for pieceNumber in range(0, len(pieces)-1):\n",
    "        nameVersion += initials[pieceNumber]\n",
    "    nameVersion += ' ' + pieces[len(pieces)-1]\n",
    "    alternatives.append(nameVersion)\n",
    "    \n",
    "    # remove duplicates\n",
    "    dedupe = list(set(alternatives))\n",
    "\n",
    "    return dedupe\n",
    "\n",
    "def searchNameAtWikidata(name):\n",
    "    nameList = generateNameAlternatives(name)\n",
    "    alternatives = ''\n",
    "    for alternative in nameList:\n",
    "        alternatives += '\"' + alternative + '\"@en\\n'\n",
    "    query = '''\n",
    "select distinct ?item where {\n",
    "  VALUES ?value\n",
    "  {\n",
    "  ''' + alternatives + '''}\n",
    "?item rdfs:label|skos:altLabel ?value.\n",
    "  }\n",
    "'''\n",
    "    #print(query)\n",
    "    print('searching for ', name)\n",
    "    results = searchWikidataForQId(query)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bsci-employees-with-orcid.csv'\n",
    "bsciEmployees = readDict(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'vanderbilt_wikidata.csv'\n",
    "wikidataData = readDict(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testRatio = 90\n",
    "departmentTestRatio = 90\n",
    "\n",
    "for employeeIndex in range(0, len(bsciEmployees)):\n",
    "    # 0=unmatched\n",
    "    # 1=matched with ORCID in both sources\n",
    "    # 2=ORCID in BSCI but name match to Wikidata (no ORCID)\n",
    "    # 3=no ORCID in BSCI but name match to Wikidata (with ORCID); could happen if affiliation isn't matched in ORCID\n",
    "    # 4=no ORCID in BSCI but name match to Wikidata (no ORCID)\n",
    "    # 5=ORCID in BSCI and found via SPARQL ORCID search (likely non-VU affiliated in Wikidata)\n",
    "    # 6=ORCID in BSCI and found via SPARQL name search (non-VU affiliated without ORCID)\n",
    "    # 7=no ORCID in BSCI, no name match\n",
    "    # 8=ORCID in BSCI, error in SPARQL ORCID search\n",
    "    # 9=no ORCID in BSCI, error in SPARQL name search\n",
    "    matchStatus = 0\n",
    "    for row in wikidataData:\n",
    "        # We know the employee has an ORCID, so try to match it\n",
    "        if bsciEmployees[employeeIndex]['orcid'] != '':\n",
    "            # There's a match, hooray!\n",
    "            if bsciEmployees[employeeIndex]['orcid'] == row['orcid']:\n",
    "                print('orcid match: ', row['name'] + ' ' + row['orcid'])\n",
    "                matchStatus = 1\n",
    "                bsciEmployees[employeeIndex]['wikidataId'] = extractQNumber(row['wikidataIri'])\n",
    "            # No ORCID match - see if the name matches\n",
    "            else:\n",
    "                setRatio = fuzz.token_set_ratio(row['name'], bsciEmployees[employeeIndex]['name'])\n",
    "                if setRatio >= testRatio:\n",
    "                    print('name match: ', str(setRatio) + ' ' + row['name'] + ' / ' + bsciEmployees[employeeIndex]['name'] + ' BSCI:' + bsciEmployees[employeeIndex]['orcid'])\n",
    "                    matchStatus = 2\n",
    "                    bsciEmployees[employeeIndex]['wikidataId'] = extractQNumber(row['wikidataIri'])\n",
    "        # As far as we know, the employee doesn't have an ORCID, so try to match the name\n",
    "        else:\n",
    "            setRatio = fuzz.token_set_ratio(row['name'], bsciEmployees[employeeIndex]['name'])\n",
    "            # We get a name match \n",
    "            if setRatio >= testRatio:\n",
    "                # For some reason, Wikidata has the ORCID, so grab it\n",
    "                if row['orcid'] != '':\n",
    "                    print('name match: ', str(setRatio) + ' ' + row['name'] + ' / ' + bsciEmployees[employeeIndex]['name'] + ' ORCID:' + row['orcid'])\n",
    "                    bsciEmployees[employeeIndex]['orcid'] = row['orcid']\n",
    "                    matchStatus = 3\n",
    "                # Wikidata doesn't have an ORCID\n",
    "                else:\n",
    "                    print('name match: ', str(setRatio) + ' ' + row['name'] + ' / ' + bsciEmployees[employeeIndex]['name'] + ' WD description: ' + row['description'])\n",
    "                    matchStatus = 4\n",
    "                bsciEmployees[employeeIndex]['wikidataId'] = extractQNumber(row['wikidataIri'])\n",
    "        # We've gone all the way through the without finding a match\n",
    "\n",
    "    # Do a last ditch attempt to try to find the person in Wikidata by doing a SPARQL search for their ORCID\n",
    "    if matchStatus == 0:\n",
    "        if bsciEmployees[employeeIndex]['orcid'] != '':\n",
    "            query = '''\n",
    "select distinct ?item where {\n",
    "  ?item wdt:P496 \"''' + bsciEmployees[employeeIndex]['orcid'] + '''\".\n",
    "  }\n",
    "'''\n",
    "            results = searchWikidataForQId(query)\n",
    "            if len(results) > 0:\n",
    "                print('SPARQL ORCID search: ', bsciEmployees[employeeIndex]['name'], results)\n",
    "                if len(results) == 1:\n",
    "                    # if search fails and return an error message\n",
    "                    if len(results[0]) > 15:\n",
    "                        matchStatus = 8\n",
    "                        print('Error message in ORCID search')\n",
    "                    else:\n",
    "                        matchStatus = 5\n",
    "                        bsciEmployees[employeeIndex]['wikidataId'] = results[0]\n",
    "                else:\n",
    "                    print('ERROR: multiple results for same ORCID')\n",
    "        # try a name search as a last resort\n",
    "        # NOTE: There is a significant number of cases where the person has an ORCID and is in Wikidata\n",
    "        # but we don't know their ORCID because their affiliation didn't get into Wikidata or ORCID\n",
    "        # These cases will need to be checked manually against publications to make sure they are \n",
    "        # the right people.\n",
    "        else:\n",
    "            results = searchNameAtWikidata(bsciEmployees[employeeIndex]['name'])\n",
    "            if len(results) > 0:\n",
    "                print('SPARQL name search: ', bsciEmployees[employeeIndex]['name'], results)\n",
    "                if len(results) == 1:\n",
    "                    # check for error message in results\n",
    "                    if len(results[0]) > 15:\n",
    "                        matchStatus = 9\n",
    "                        print('Error message in name search')\n",
    "                    else:\n",
    "                        matchStatus = 6\n",
    "            else:\n",
    "                print('No Wikidata match: ', bsciEmployees[employeeIndex]['name'])\n",
    "                matchStatus = 7\n",
    "        bsciEmployees[employeeIndex]['wikidataStatus'] = str(matchStatus)\n",
    "\n",
    "print('done')\n",
    "print(bsciEmployees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bsci-employees-with-wikidata.csv'\n",
    "with open(filename, 'w', newline='') as csvFileObject:\n",
    "    fieldnames = ['wikidataId', 'name', 'degree', 'category', 'orcid', 'wikidataStatus', 'role']\n",
    "    writer = csv.DictWriter(csvFileObject, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in bsciEmployees:\n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
