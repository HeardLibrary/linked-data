{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transfer_to_vanderbot.ipynb, a Python script for linking Wikimedia Commons artwork images with Wikidata items for those images. \n",
    "# It uses CSV output from commonsbot.ipynb (https://github.com/HeardLibrary/linked-data/blob/master/commonsbot/commonsbot.ipynb) \n",
    "# and produces input for VanderBot (https://github.com/HeardLibrary/linked-data/tree/master/vanderbot) by \n",
    "# modifying an existing VanderBot-formatted CSV file.\n",
    "version = '0.1'\n",
    "created = '2021-12-10'\n",
    "\n",
    "# (c) 2021 Vanderbilt University. This program is released under a GNU General Public License v3.0 http://www.gnu.org/licenses/gpl-3.0\n",
    "# Author: Steve Baskauf\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Configuration\n",
    "public_domain_categories = [\n",
    "    {'reason': 'artist died before copyright cutoff', 'applies': 'Q60332278', 'method': 'Q29940705'}, #100 years or more after author's death\n",
    "    {'reason': 'artist was born before 1800', 'applies': 'Q60332278', 'method': 'Q29940705'}, # 100 years or more after author's death\n",
    "    {'reason': 'assessed to be out of copyright', 'applies': 'Q60332278', 'method': 'Q61848113'}, # determined by GLAM institution and stated at its website\n",
    "    {'reason': 'from style or period that ended prior to copyright cutoff', 'applies': 'Q30', 'method': 'Q47246828'}, # published more than 95 years ago\n",
    "    {'reason': 'inception prior to copyright cutoff', 'applies': 'Q30', 'method': 'Q47246828'} #published more than 95 years ago\n",
    "]\n",
    "\n",
    "# Set these paths based on your local configuration\n",
    "image_data_directory = '/users/baskausj/github/vandycite/gallery_works/image_upload/'\n",
    "works_data_directory = '/users/baskausj/github/vandycite/gallery_works/'\n",
    "\n",
    "# Function definitions\n",
    "def generate_utc_date():\n",
    "    whole_time_string_z = datetime.datetime.utcnow().isoformat() # form: 2019-12-05T15:35:04.959311\n",
    "    date_z = whole_time_string_z.split('T')[0] # form 2019-12-05\n",
    "    return date_z\n",
    "\n",
    "# Load data\n",
    "today = generate_utc_date()\n",
    "\n",
    "# These files are somewhat idiosyncratic and the output of other scripts as detailed.\n",
    "\n",
    "# This file is the general Wikidata metadata storage file based on the Vanderbot CSV format.\n",
    "# For the column header setup, see the sample file and config.json used to generate csv-metadata.json files.\n",
    "# In the example, the image, copyright_status, and iiif_manifest related columns are blank, since they will be filled in by this script.\n",
    "# In reality this work already has values for those properties.\n",
    "works_metadata = pd.read_csv(works_data_directory + 'works_multiprop.csv', na_filter=False, dtype = str) # Don't make the Q IDs the index!\n",
    "\n",
    "# This file is the output of commonsbot\n",
    "existing_images = pd.read_csv(image_data_directory + 'commons_images.csv', na_filter=False, dtype = str) # Don't make the Q IDs the index\n",
    "\n",
    "# This file was the result of an idiosynctratic script to determine copyright status of Vanderbilt gallery works.\n",
    "# See the example file for format.\n",
    "works_ip_status = pd.read_csv(works_data_directory + 'items_status_abbrev.csv', na_filter=False, dtype = str)\n",
    "works_ip_status.set_index('qid', inplace=True) # use the Q ID as the index\n",
    "\n",
    "# Transfer data to metadata file used by VanderBot for upload\n",
    "\n",
    "# Step through the list of files with uploaded images to check if their image data need to be transferred to works metadata\n",
    "items_transferred = 0\n",
    "for index, work in existing_images.iterrows():\n",
    "    \n",
    "    # If the work failed to upload, skip it.\n",
    "    if work['commons_id'] == 'error':\n",
    "        continue\n",
    "        \n",
    "    # Check to make sure that there is a single row that matches the Q ID of the work to be updated\n",
    "    qid = work['qid']\n",
    "    # Search in the qid column of the works metadata to find rows that match the current item qid\n",
    "    row_series = works_metadata[works_metadata['qid'].str.contains(qid)]\n",
    "    if len(row_series) == 0:\n",
    "        print('uploaded image Wikidata record for', qid, 'not found in works metadata.')\n",
    "        continue # skip to next uploaded image\n",
    "    elif len(row_series) >= 2:\n",
    "        print('more than Wikidata record found for', qid, 'in works metadata.')\n",
    "        continue # skip to next uploaded image\n",
    "        \n",
    "    # Series have only one dimension, so the value returned for the .index method has only one (0th) item.\n",
    "    row_index = row_series.index[0]\n",
    "\n",
    "    #Transfer image name data\n",
    "\n",
    "    # Transfer the image data only if the uploaded data item has an image name.\n",
    "    if work['image_name'] != '':\n",
    "        # The result of getting the image_uuid item is itself a series, so its\n",
    "        # Numpy array has to be accessed in order to address its first item 0.\n",
    "        #print(row_series['image_uuid'].array[0])\n",
    "        if row_series['image_uuid'].array[0] == '': # If image is already uploaded, it will have a UUID\n",
    "            # Find the image name and insert it into the works metadata DataFrame\n",
    "            image_name = work['image_name']\n",
    "            print('transferring image name for', qid, ':', image_name)\n",
    "            works_metadata.at[row_index, 'image'] = image_name\n",
    "    \n",
    "    # Transfer IIIF manifest URLs\n",
    "    if work['iiif_manifest'] != '':\n",
    "        if row_series['iiif_manifest_uuid'].array[0] == '': # If image is already uploaded, it will have a UUID\n",
    "            manifest_url = work['iiif_manifest']\n",
    "            print('transferring manifest', qid, ':', manifest_url)\n",
    "            works_metadata.at[row_index, 'iiif_manifest'] = manifest_url\n",
    "    \n",
    "    # Generate statements and qualifiers for public domain copyright status\n",
    "    if work['local_filename'] != '': # skip works that weren't uploaded by us\n",
    "        if row_series['copyright_status_uuid'].array[0] == '': # skip if the copyright status is already in the data\n",
    "            if qid in works_ip_status.index: # only do this processing step if the work was in the assessment file\n",
    "                ip_status = works_ip_status.loc[qid, 'status']\n",
    "                for category in public_domain_categories: # only one (or none) of these categories is possible, images with empty cells can't be uploaded\n",
    "                    if ip_status == category['reason']:\n",
    "                        print('Writing copyright status for', qid)\n",
    "                        works_metadata.at[row_index, 'copyright_status'] = 'Q19652' # set status to Public Domain\n",
    "                        works_metadata.at[row_index, 'copyright_status_applies_to_jurisdiction'] = category['applies']\n",
    "                        works_metadata.at[row_index, 'copyright_status_determination_method'] = category['method']\n",
    "                        # all of the images being added will have inventory numbers, so safe to use this:\n",
    "                        works_metadata.at[row_index, 'copyright_status_ref1_referenceUrl'] = row_series['inventory_number_ref1_referenceUrl'].array[0]\n",
    "                        works_metadata.at[row_index, 'copyright_status_ref1_retrieved_val'] = today\n",
    "\n",
    "# Write the updated dataframe to CSV\n",
    "works_metadata.to_csv(works_data_directory + 'works_multiprop.csv', index = False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
